<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"allen108108.github.io","root":"/blog/","images":"/blog/images","scheme":"Gemini","version":"8.7.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":280},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/blog/js/config.js"></script>
<meta name="description" content="&quot; What I cannot create, I do not understand. &quot; --- Richard Feynman  我們想要知道機器是不是真的能學到東西，直覺得就是他能不能夠根據它所學到的東西進行創造，創造出可以以假亂真的成品出來。">
<meta property="og:type" content="article">
<meta property="og:title" content="Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )">
<meta property="og:url" content="https://allen108108.github.io/blog/2019/10/08/Unsupervised%20Learning%20(6)%20--%20Generation%20(%20PixelRNN%E3%80%81Variational%20Auto-Encoder%20(%20VAE%20)%20)/index.html">
<meta property="og:site_name" content="Math.py">
<meta property="og:description" content="&quot; What I cannot create, I do not understand. &quot; --- Richard Feynman  我們想要知道機器是不是真的能學到東西，直覺得就是他能不能夠根據它所學到的東西進行創造，創造出可以以假亂真的成品出來。">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://i.imgur.com/YUBN2qQ.png%20=400x">
<meta property="og:image" content="https://i.imgur.com/gwkOoAb.png">
<meta property="og:image" content="https://i.imgur.com/0bpPzmF.png%20=450x">
<meta property="og:image" content="https://i.imgur.com/JoNfLCr.png">
<meta property="og:image" content="https://i.imgur.com/eePORC5.png">
<meta property="og:image" content="https://i.imgur.com/hUFoG9E.gif">
<meta property="og:image" content="https://i.imgur.com/uLklWnd.jpg">
<meta property="og:image" content="https://i.imgur.com/ZYG02PE.png">
<meta property="og:image" content="https://i.imgur.com/sKl5XPV.png">
<meta property="og:image" content="https://i.imgur.com/bWYFJnx.png">
<meta property="og:image" content="https://i.imgur.com/V78Tv6m.png">
<meta property="og:image" content="https://i.imgur.com/phsgs2U.png">
<meta property="og:image" content="https://i.imgur.com/Rgoqgqq.png%20=300x">
<meta property="og:image" content="https://i.imgur.com/6glyfff.png">
<meta property="og:image" content="https://i.imgur.com/Nrxug09.jpg">
<meta property="og:image" content="https://i.imgur.com/IenlZLA.png">
<meta property="article:published_time" content="2019-10-07T16:47:56.000Z">
<meta property="article:modified_time" content="2019-11-02T17:54:00.856Z">
<meta property="article:author" content="Allen Tzeng">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.imgur.com/YUBN2qQ.png%20=400x">


<link rel="canonical" href="https://allen108108.github.io/blog/2019/10/08/Unsupervised%20Learning%20(6)%20--%20Generation%20(%20PixelRNN%E3%80%81Variational%20Auto-Encoder%20(%20VAE%20)%20)/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://allen108108.github.io/blog/2019/10/08/Unsupervised%20Learning%20(6)%20--%20Generation%20(%20PixelRNN%E3%80%81Variational%20Auto-Encoder%20(%20VAE%20)%20)/","path":"2019/10/08/Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )/","title":"Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) ) | Math.py</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-149442581-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-149442581-1","only_pageview":false}</script>
  <script src="/blog/js/third-party/analytics/google-analytics.js"></script>




  <noscript>
    <link rel="stylesheet" href="/blog/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Math.py</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Wir müssen wissen , wir werden wissen</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li>
        <li class="menu-item menu-item-categories"><a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li>
        <li class="menu-item menu-item-archives"><a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#pixelrnn"><span class="nav-number">1.</span> <span class="nav-text">PixelRNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#recurrent-neural-networks-rnn-%E9%81%9E%E6%AD%B8%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF"><span class="nav-number">1.1.</span> <span class="nav-text">Recurrent Neural Networks ( RNN , 遞歸神經網路 )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pixelrnn-1"><span class="nav-number">1.2.</span> <span class="nav-text">PixelRNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#variational-auto-encoder-vae"><span class="nav-number">2.</span> <span class="nav-text">Variational Auto-Encoder ( VAE )</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%9E-gaussian-mixture-model-%E8%A7%92%E5%BA%A6%E4%BE%86%E7%9C%8B-vae"><span class="nav-number">2.1.</span> <span class="nav-text">從 Gaussian Mixture Model 角度來看 VAE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%9E-regularization-%E8%A7%92%E5%BA%A6%E4%BE%86%E7%9C%8B-vae"><span class="nav-number">2.2.</span> <span class="nav-text">從 Regularization 角度來看 VAE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mathematics-in-vae-%E6%95%B4%E5%90%88%E8%A8%B1%E5%A4%9A%E8%B3%87%E6%96%99%E5%BE%8C%E7%9A%84%E7%AD%86%E8%A8%98"><span class="nav-number">2.3.</span> <span class="nav-text">Mathematics in VAE ( 整合許多資料後的筆記 )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#controlability-of-vae"><span class="nav-number">2.4.</span> <span class="nav-text">Controlability of VAE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#problems-of-vae"><span class="nav-number">2.5.</span> <span class="nav-text">Problems of VAE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A8%BB%E9%87%8B"><span class="nav-number">3.</span> <span class="nav-text">註釋</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Allen Tzeng"
      src="/blog/images/allen.jpg">
  <p class="site-author-name" itemprop="name">Allen Tzeng</p>
  <div class="site-description" itemprop="description">Study about Mathematics , Programming and Data Science</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/blog/archives/">
          <span class="site-state-item-count">118</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/blog/categories/">
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://allen108108.github.io/" title="Github page → https:&#x2F;&#x2F;allen108108.github.io&#x2F;"><i class="github-alt fa-fw"></i>Github page</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/allen108108" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;allen108108" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:allen108108@hotmail.com" title="E-Mail → mailto:allen108108@hotmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



          </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://allen108108.github.io/blog/2019/10/08/Unsupervised%20Learning%20(6)%20--%20Generation%20(%20PixelRNN%E3%80%81Variational%20Auto-Encoder%20(%20VAE%20)%20)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/allen.jpg">
      <meta itemprop="name" content="Allen Tzeng">
      <meta itemprop="description" content="Study about Mathematics , Programming and Data Science">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Math.py">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2019-10-08 00:47:56" itemprop="dateCreated datePublished" datetime="2019-10-08T00:47:56+08:00">2019-10-08</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新於</span>
        <time title="修改時間：2019-11-03 01:54:00" itemprop="dateModified" datetime="2019-11-03T01:54:00+08:00">2019-11-03</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E8%AA%B2%E7%A8%8B%E7%AD%86%E8%A8%98-Course/" itemprop="url" rel="index"><span itemprop="name">課程筆記 Course</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E8%AA%B2%E7%A8%8B%E7%AD%86%E8%A8%98-Course/%E6%9D%8E%E5%AE%8F%E6%AF%85-Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">李宏毅 Machine Learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="閱讀次數" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">閱讀次數：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/blog/2019/10/08/Unsupervised%20Learning%20(6)%20--%20Generation%20(%20PixelRNN%E3%80%81Variational%20Auto-Encoder%20(%20VAE%20)%20)/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/08/Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>" What I cannot create, I do not understand. " --- Richard Feynman</p>
</blockquote>
<p>我們想要知道機器是不是真的能學到東西，直覺得就是他能不能夠根據它所學到的東西進行創造，創造出可以以假亂真的成品出來。</p>
<span id="more"></span>
<p><img src="https://i.imgur.com/YUBN2qQ.png%20=400x" /></p>
<h2 id="pixelrnn">PixelRNN</h2>
<h3 id="recurrent-neural-networks-rnn-遞歸神經網路">Recurrent Neural Networks ( RNN , 遞歸神經網路 )</h3>
<p>在講 PixelRNN 以前，我們要先簡單的了解 Recurrent Neural Networks ( RNN , 遞歸神經網路 )是什麼。由於在後面的課程中，李宏毅老師會有一整個 Lecture 來講 RNN，這邊我們大概解釋一下 RNN 的精神即可。</p>
<p>簡單的來說，在現實生活中，會有許多決策會由於時間序列推移，導致前一次的決策影響下一次的決策，如此遞迴下去，而 RNN 正是處理這樣問題的神經網路系統。以下是很常看到的例子 :</p>
<p><img src="https://i.imgur.com/gwkOoAb.png" /> (圖片來源 : <a target="_blank" rel="noopener" href="https://brohrer.github.io/how_rnns_lstm_work.html">How Recurrent Neural Networks and Long Short-Term Memory Work</a>)</p>
<p>每一天的晚餐都會因為前一天晚餐而有所影響，利用 RNN 我們就可以做出當天晚餐的預測。</p>
<h3 id="pixelrnn-1">PixelRNN</h3>
<p>PixelRNN 是一種直觀的方式，利用前一個 pixel 讓機器預測下一個 pixel，藉此完成一整張圖片。</p>
<p><img src="https://i.imgur.com/0bpPzmF.png%20=450x" /></p>
<p>雖然說這樣的方式太過直覺，但實際上進行預測，仍能生成出蠻合理的圖片。以下是李宏毅老師利用神奇寶貝 ( 寶可夢，Pokémon ) 來試圖生成新的神奇寶貝圖片。</p>
<p>實務上進行生成會有一些問題，因此李宏毅老師進行了一些原始資料的預處理。</p>
<ul>
<li>原本圖片都是 <span class="math inline">\(40\times 40\)</span> ，這樣維度太高，因此截取中間的 <span class="math inline">\(20\times 20\)</span> 作為輸入</li>
<li>進行生成時會發現圖片都偏灰暗，表示其 RGB 預測值對比度低，所以先對原始圖像 pixel 進行 1-of-N Encoding，再將相似色 clustering，最後一共有 167 種顏色分類。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<p>最後利用一個 1-layer LSTM 不調太多參數來生成圖片。</p>
<p><img src="https://i.imgur.com/JoNfLCr.png" /> ( 第一列為原始圖片，第二列是給上半部50%讓機器預測下面50%，第三列則是給上半部25%讓祭器預測下面75% )</p>
<p>當然也可以不給機器前一部分，讓它自己畫出整個圖片</p>
<p><img width=500 src="https://i.imgur.com/eePORC5.png" ></p>
<p>然而，PixelRNN 不只是只能用於圖像上，我們可以利用這樣的概念進行語音或影片的生成。</p>
<p><img src="https://i.imgur.com/hUFoG9E.gif" /></p>
<h2 id="variational-auto-encoder-vae">Variational Auto-Encoder ( VAE )</h2>
<p>先前我們提到 Auto-Encoder 意圖讓原本的圖片 encoder 壓縮成更低維度但仍保有原始資料資訊的 " code " 再由 decoder 還原回去。如果訓練出一組 Auto-Encoder，是否可以輸入一組隨機的 code 利用 decoder 畫出更接近真實的圖片呢 ?</p>
<p>很遺憾的，這樣子的方式生成的圖片都不會太理想。 原因其實可以簡單的這樣解釋，我們隨機給予的 code 並不是由圖片 encoder 而得，所以不見得會帶有 information，那想當然爾，經過 decoder 生成的圖片便不見得會有我們期待的結果出現，甚至可能生成出完全沒有意義的圖片。<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>為了要解決這樣的問題，出現了 " Variational Auto-Encoder ( VAE ) "</p>
<p><img src="https://i.imgur.com/uLklWnd.jpg" /></p>
<h3 id="從-gaussian-mixture-model-角度來看-vae">從 Gaussian Mixture Model 角度來看 VAE</h3>
<p>要理解 VAE 以前，我們先回顧一下，原本的 AE 是將輸入轉換成一個 information preserving " CODE "，也可以看成是一組低維度的隱藏特徵，每一個特徵上給予一個數值。</p>
<p><img src="https://i.imgur.com/ZYG02PE.png" /> (圖片來源 : <a target="_blank" rel="noopener" href="https://www.jeremyjordan.me/variational-autoencoders/">Variational autoencoders.</a>)</p>
<p>而 VAE 則可以看做是這些隱含特徵的 Gaussian Mixture Model，也就是說，我們將每一個隱含特徵上都給予其機率分布，而這些分布經由加權總合後形成一個輸入的分布 。我們也可以從另外一個角度來看 VAE，VAE 相當於在輸入加入一些 Noise ，讓整個模型有更好的泛化能力，能夠解決生成圖像不連續的狀況。</p>
<p><img src="https://i.imgur.com/sKl5XPV.png" /></p>
<h3 id="從-regularization-角度來看-vae">從 Regularization 角度來看 VAE</h3>
<p>我們可以從正則化 (regularization) 的角度來看 VAE。一般的 AE 再進行訓練的時候，為了將 reconstruct error 壓低，因此很容易讓整個模型產生 overfitting 的狀況，這也是為什麼我們隨機給予一個 CODE ，卻很可能會生成出沒有意義的圖片。</p>
<p><img src="https://i.imgur.com/bWYFJnx.png" /> (圖片來源 :<a target="_blank" rel="noopener" href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73">Understanding Variational Autoencoders (VAEs)</a>)</p>
<p>VAE 的產生便是為了加強模型的正則化，讓整個 model 的泛化能力更強。VAE 採取的正則化方式就是讓整個 encoder 不再將輸入 map 到單一個點，而是 map 到一個具有某些限制的常態分佈 (normal distribution)。</p>
<p><img width=500 src="https://i.imgur.com/V78Tv6m.png" > (圖片來源 :<a target="_blank" rel="noopener" href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73">Understanding Variational Autoencoders (VAEs)</a>)</p>
<h3 id="mathematics-in-vae-整合許多資料後的筆記">Mathematics in VAE ( 整合許多資料後的筆記 )</h3>
<p>VAE 的概念發想是這樣，我們假設有一堆隱含特徵 ( Laten Features ) <span class="math inline">\(z\)</span> 可經由 <span class="math inline">\(P_{\theta}(x\mid z)\)</span> 生成出觀測資料 <span class="math inline">\(x\)</span>，其中 <span class="math inline">\(\theta\)</span> 表示生成 <span class="math inline">\(x\)</span> 的模型中所需要的參數。在自然界中，我們可以合理的假設 <span class="math inline">\(z\)</span> 的分布是一個常態分布。</p>
<p><span class="math display">\[
z\sim N(0,I)
\]</span></p>
<p><img src="https://i.imgur.com/phsgs2U.png" /></p>
<p>從 Gaussian Mixture Model 來看，我們可以利用各種不同的 Gaussian Distribution 來逼近真實的 <span class="math inline">\(x\)</span> 的分布。</p>
<p><span class="math display">\[
P(x)=\int\limits_{z}P_{\theta}(z)P_{\theta}(x\mid z)dz
\]</span></p>
<p><span class="math inline">\(x\)</span> 是我們觀察到的資料，就機率而言，能讓我們看到的資料必然是出現的機率很大才會這麼容易讓我們觀察到，所以我們要做的就是將上式最大化。</p>
<p><span class="math inline">\(P_{\theta}(z)\)</span> 是一個常態分佈，而給定一個 <span class="math inline">\(z\)</span> 我們要找出 <span class="math inline">\(P_{\theta}(x\mid z)\)</span> 也是沒有問題的。但麻煩的是這個積分我們無法計算，如果 <span class="math inline">\(z\)</span> 的維度很高，我們必須要處理很大量的多重積分，大部分的狀況都無法處理。</p>
<p>不能直接對資料的 Likelihood 作最大化，那換個方向，處理後驗分布 <span class="math inline">\(P_{\theta}(z\mid x)\)</span> 好 了。</p>
<p><span class="math display">\[
P_{\theta}(z\mid x) = \displaystyle{\frac{P_{\theta}(x\mid z)\cdot P_{\theta}(z)}{P_{\theta}(x)}}
\]</span></p>
<p>這個方向仍然要面對 <span class="math inline">\(P_{\theta}(x)\)</span> 也是死路一條。</p>
<p>在 VAE 原始論文<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>中利用 Log data likelihood ，並試圖用另外一個分布 <span class="math inline">\(q_{\phi}(z\mid x)\)</span> 來逼近 <span class="math inline">\(P_{\theta}(x\mid z)\)</span>。</p>
<p><img src="https://i.imgur.com/Rgoqgqq.png%20=300x" /></p>
<p><span class="math display">\[
\log P_{\theta}(x)=\max\log P_{\theta}(x)\cdot\int\limits_{z} q_{\phi}(z\mid x)dz\\
=\int\limits_{z} q_{\phi}(q_{\phi}z\mid x)\log P_{\theta}(x)dz\\
=\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{P_{\theta}(x,z)}{P_{\theta}(z\mid x)}}\Big)dz\\
=\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{P_{\theta}(x,z)}{q_{\phi}(z\mid x)}}\cdot\displaystyle{\frac{q_{\phi}(z\mid x)}{P_{\theta}(z\mid x)}}\Big)dz\\
=\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{P_{\theta}(x,z)}{q_{\phi}(z\mid x)}}\Big)dz+\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{q_{\phi}(z\mid x)}{P_{\theta}(z\mid x)}}\Big)dz\\
=\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{P_{\theta}(x,z)}{q_{\phi}(z\mid x)}}\Big)dz+KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z\mid x)\big)\\
=\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{P_{\theta}(x\mid z)\cdot P_{\theta}(z)}{q_{\phi}(z\mid x)}}\Big)dz+KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z\mid x)\big)\\
=\int\limits_{z}q_{\phi}(z\mid x)\log P_{\theta}(x\mid z)dz+\int\limits_{z} q_{\phi}(z\mid x)\log\Big( \displaystyle{\frac{P_{\theta}(z)}{q_{\phi}(z\mid x)}}\Big)dz+KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z\mid x)\big)\\
=\int\limits_{z}q_{\phi}(z\mid x)\log P_{\theta}(x\mid z)dz+(-KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z)\big))+KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z\mid x)\big)\\
=\int\limits_{z}q_{\phi}(z\mid x)\log P_{\theta}(x\mid z)dz-KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z)\big))+KL\big(q_{\phi}(z\mid x)\|P_{\theta}(z\mid x)\big)\\
=\int\limits_{z}q_{\phi}(z\mid x)\log P_{\theta}(x\mid z)dz-KL_a+KL_b\\
=\boldsymbol{E}_{q_{\phi}(z\mid x)}\big(\log P_{\theta}(x\mid z)\big)-KL_a+KL_b\\
\geq \boldsymbol{E}_{q_{\phi}(z\mid x)}\big(\log P_{\theta}(x\mid z)\big)-KL_a\overset{let}{=}\mathcal{L}(x,\theta,\phi)\cdots\cdots(1) 
\]</span> (這裡牽扯到 KL Divergence (KL散度) 的幾個性質，我就放在註釋內 <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>)</p>
<ol type="1">
<li>式中，<span class="math inline">\(\mathcal{L}\)</span> 即為 <span class="math inline">\(\log P_{\theta}(x)\)</span> 的下界，如果我們要最大化 <span class="math inline">\(\log P_{\theta}(x)\)</span> ，我們只要專注在最大化它的下界 <span class="math inline">\(\mathcal{L}\)</span> 即可。</li>
</ol>
<p><span class="math inline">\(\mathcal{L}\)</span> 的第一項，我們可以利用 Monte Carlo gradient estimator ( 蒙地卡羅梯度估計 ) 來進行推估，而第二項則因為我們對 <span class="math inline">\(P_{\theta}(z)\)</span> 已經先做了它是 Gaussian Distribution 的假設，所以這項就是在計算 <span class="math inline">\(q_{\phi}(z\mid x)\)</span> 與一個 Gaussian Distribution 有多相似，這會存在一個 Close-Form Solution，因此要對 <span class="math inline">\(\mathcal{L}\)</span> 進行優化是沒有問題的。</p>
<p>關於 <span class="math inline">\(\mathcal{L}\)</span> 我們還可以有一些很直覺的觀察 :</p>
<p>當我們要對 <span class="math inline">\(\mathcal{L}\)</span> 進行最大化的同時，我們也同時在對於它的第一項最大化，第二項最小化。而第一項代表的意義就是 likelihood 的期望值，第二項則代表的是 encoder network 的分布與 Gaussian Distribution 之間的相似度。</p>
<p>所以當我們在訓練的時候，對於 <span class="math inline">\(\mathcal{L}\)</span> 進行梯度優化的過程中，相對地希望根據 <span class="math inline">\(z\)</span> 生成的 <span class="math inline">\(x\)</span> 可以與我們的觀測越接近越好，同時也希望這個 encoder 分布與 Gaussian Distribution 越接近越好。</p>
<p>理論到這邊差不多告一個段落，我們也可以利用上面的這些論點來製造一個 VAE model</p>
<p><img src="https://i.imgur.com/6glyfff.png" /> (圖片來源 : Fei-Fei Li &amp; Justin Johnson &amp; Serena Yeung Lecture 13 - 88 May 18, 2017)</p>
<p>這是一個理論上簡單的VAE model，但仔細看這樣的 model 跟李宏毅課程中 VAE model 還是有幾個不一樣的小地方 :</p>
<ol type="1">
<li>在 Encoder NN 後產生的 <span class="math inline">\(\sigma\)</span> 取指數在與一個隨機的 <span class="math inline">\(e\)</span> 相加，目的在對輸入加入一些 Noise，讓整個 model 有抗噪的能力。</li>
<li>在 Decoder NN 後我們一般直接以 <span class="math inline">\(\mu_{x\mid z}\)</span> 來生成 <span class="math inline">\(x\)</span>，也因此在很多的資料上，我們在 Decoder 的部分都不會看見其同時生成 <span class="math inline">\(\mu\)</span> 與 <span class="math inline">\(\sigma\)</span> 再來生成 <span class="math inline">\(x\)</span>。</li>
</ol>
<h3 id="controlability-of-vae">Controlability of VAE</h3>
<p>了解 VAE 的運作之後，可以知道 VAE 的圖像生成具有遷移性，那麼我們便可以調整隱含特徵來了解每一個維度個代表著什麼意義。</p>
<p>若我們只取其中兩維，其他維度均固定</p>
<p><img src="https://i.imgur.com/Nrxug09.jpg" /></p>
<p>根據這兩維的調整我們可以瞭解其中一個維度代表著可能是微笑程度，另一維度則可能代表的是頭的角度。整個 VAE 便具有比 PixelRNN 更強的解釋性。</p>
<h3 id="problems-of-vae">Problems of VAE</h3>
<p>然而，整個 VAE 學習生成圖片的方式是經由數值方式優化的結果，整個 model 其實並沒有學習到 「怎麼生成圖片」這件事情。所以只要在數值優化的過程中，符合優化的結果，圖像如何呈現、是否合理，VAE 本身並不會在意。</p>
<p><img src="https://i.imgur.com/IenlZLA.png" /></p>
<p>上途中， " Realistic " 與 " Fake " 都與我們現實的圖像僅一個 pixel 的差異，以 VAE 的角度來看，這兩者都是可以接受的成像，但就現實來看 " Fake " 的成像其實很有可能是另外一個類別的圖像。</p>
<h2 id="註釋">註釋</h2>
<p><span class="math inline">\(KL( P\|Q)=\)</span> KL Divergence of Q with respect to P <span class="math inline">\(\overset{defn}{=}-\sum P(x)\log\Big(\displaystyle{\frac{Q(x)}{P(x)}}\Big)\)</span> (a) <span class="math inline">\(KL\geq 0\cdots KL\)</span>恆大於零 (b) <span class="math inline">\(KL(P\|Q)\neq KL(Q\| P)\cdots KL\)</span> 不具對稱性</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>李宏毅老師將其資料都放在下列網址，可以進行使用 * Original image (40 x 40): (http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/image.rar) * Pixels (20 x 20): (http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/pixel_color.txt) * Each line corresponds to an image, and each number corresponds to a pixel (http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_cre)<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>可參考 " <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27549418">花式解释AutoEncoder与VAE</a> " 一文<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Kingma, Diederik P. and Max Welling. “<em>Auto-Encoding Variational Bayes.</em>” CoRR abs/1312.6114 (2014): n. pag.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>KL Divergence ( KLD，KL散度，相對熵 ) : 簡單來說，這是一個衡量兩個分布相似度的方式，有些人會解釋成兩個分布的「距離」，但如果從 KLD 的性質來看會發現用距離來形容它的確不太恰當。<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>作者： </strong>Allen Tzeng
  </li>
  <li class="post-copyright-link">
      <strong>文章連結：</strong>
      <a href="https://allen108108.github.io/blog/2019/10/08/Unsupervised%20Learning%20(6)%20--%20Generation%20(%20PixelRNN%E3%80%81Variational%20Auto-Encoder%20(%20VAE%20)%20)/" title="Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )">https://allen108108.github.io/blog/2019/10/08/Unsupervised Learning (6) -- Generation ( PixelRNN、Variational Auto-Encoder ( VAE ) )/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版權聲明： </strong>本網誌所有文章除特別聲明外，均採用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh_TW" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 許可協議。轉載請註明出處！
  </li>
</ul>
</div>


        
  <div class="post-widgets">
    <div class="wp_rating">
      <div id="wpac-rating"></div>
    </div>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blog/2019/10/08/Unsupervised%20Learning%20(5)%20--%20Generation%20(%20%E5%88%9D%E6%8E%A2%20Generative%20Adversarial%20Network%20(%20GAN%20)%20)/" rel="prev" title="Unsupervised Learning (5) -- Generation ( 初探 Generative Adversarial Network ( GAN ) )">
                  <i class="fa fa-chevron-left"></i> Unsupervised Learning (5) -- Generation ( 初探 Generative Adversarial Network ( GAN ) )
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/blog/2019/10/08/ShuffleNet%20V2%20%E6%96%BC%20MNIST%20%E4%B8%8A%E4%B9%8B%E5%AF%A6%E4%BD%9C/" rel="next" title="ShuffleNet V2 於 MNIST 上之實作">
                  ShuffleNet V2 於 MNIST 上之實作 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Allen Tzeng</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="訪客總數">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="總瀏覽次數">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
<script src="/blog/js/comments.js"></script><script src="/blog/js/utils.js"></script><script src="/blog/js/motion.js"></script><script src="/blog/js/next-boot.js"></script><script src="/blog/js/pjax.js"></script>

  
  <script src="https://embed.widgetpack.com/widget.js" async></script>
  <script class="next-config" data-name="rating" type="application/json">{"enable":true,"id":21351,"color":"#fc6423"}</script>
  <script src="/blog/js/third-party/rating.js"></script>




  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/blog/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"math-py","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/blog/js/third-party/comments/disqus.js"></script>

</body>
</html>
